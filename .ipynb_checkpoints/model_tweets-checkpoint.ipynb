{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's model tweets with naive bayes and svm algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pickle.load(open('./data/tweets_cleaned.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 4585 tweets\n"
     ]
    }
   ],
   "source": [
    "print(\"Working with {} tweets\".format(len(tweets_df['tweets'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_df['tweets'].values\n",
    "y = tweets_df['emoji']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(list(ENGLISH_STOP_WORDS) + ['rt', 'follow', 'dm', 'https', 'ur', 'll' ,'amp', 'subscribe', 'don', 've', 'retweet', 'im', 'http','lt'])\n",
    "tfidf = TfidfVectorizer(max_features=10000, max_df = .8, min_df = .001, stop_words = stopwords, ngram_range = (1,2))\n",
    "tfidf.fit(X_train)\n",
    "X_train_tfidf = tfidf.transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  8.511870295309786\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes multinom\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_nb = nb.predict(X_test_tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "nb_score = accuracy_score(predictions_nb, y_test)*100\n",
    "print(\"Naive Bayes Accuracy Score -> \", nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy Score ->  3.1847133757961785\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes gaussian\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "gnb.fit(X_train_tfidf.todense(), y_train)\n",
    "predictions_gnb = gnb.predict(X_test_tfidf.todense())\n",
    "        \n",
    "gnb_score = accuracy_score(predictions_gnb, y_test)*100\n",
    "print(\"Gaussian Naive Bayes Accuracy Score -> \", gnb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  9.843659525188189\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', probability=True)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "# predict the labels on validation dataset\n",
    "predictions_svm = svm.predict(X_test_tfidf)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "score = accuracy_score(predictions_svm, y_test)*100\n",
    "print(\"SVM Accuracy Score -> \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "text = 'climate change'\n",
    "top_n = 5\n",
    "test_tfidf = tfidf.transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 predictions for climate change is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0.136599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>üî•</td>\n",
       "      <td>0.074257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>üò≠</td>\n",
       "      <td>0.038399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>0.032417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>ü§£</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classes     probs\n",
       "475       üòÇ  0.136599\n",
       "436       üî•  0.074257\n",
       "516       üò≠  0.038399\n",
       "536       üôÑ  0.032417\n",
       "587       ü§£  0.027200"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multinom prediction\n",
    "probs = nb.predict_proba(test_tfidf)\n",
    "predict_rank = pd.DataFrame({'classes': svm.classes_, 'probs': probs[0]})\n",
    "predict_rank = predict_rank.sort_values(by = 'probs', ascending = False)\n",
    "\n",
    "print('top {} predictions for {} is:'.format(top_n, text))\n",
    "\n",
    "predict_rank[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 predictions for climate change is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>‚ò†</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>‚è≥</td>\n",
       "      <td>6.828435e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>üå≤</td>\n",
       "      <td>4.232595e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>üëé</td>\n",
       "      <td>4.326672e-37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>üå©</td>\n",
       "      <td>4.546423e-38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classes         probs\n",
       "22        ‚ò†  1.000000e+00\n",
       "11        ‚è≥  6.828435e-23\n",
       "164       üå≤  4.232595e-23\n",
       "314       üëé  4.326672e-37\n",
       "162       üå©  4.546423e-38"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gnb prediction\n",
    "probs = gnb.predict_proba(test_tfidf.todense())\n",
    "predict_rank = pd.DataFrame({'classes': svm.classes_, 'probs': probs[0]})\n",
    "predict_rank = predict_rank.sort_values(by = 'probs', ascending = False)\n",
    "\n",
    "print('top {} predictions for {} is:'.format(top_n, text))\n",
    "\n",
    "predict_rank[:top_n]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# gnb prediction\n",
    "probs = gnb.predict_proba(test_tfidf.todense())\n",
    "above_0 = np.argwhere(probs>0).flatten()\n",
    "above_0 = np.sort(above_0)[::-1]\n",
    "print('-->',text,'=',)\n",
    "        \n",
    "for i in above_0[:top_n]:\n",
    "    print(gnb.classes_[i],' ', probs.flatten()[i],' ',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 predictions for climate change is:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>0.094941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>üî•</td>\n",
       "      <td>0.035626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>üò≠</td>\n",
       "      <td>0.033471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>ü§£</td>\n",
       "      <td>0.019915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>0.011545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    classes     probs\n",
       "475       üòÇ  0.094941\n",
       "436       üî•  0.035626\n",
       "516       üò≠  0.033471\n",
       "587       ü§£  0.019915\n",
       "536       üôÑ  0.011545"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm prediction\n",
    "probs = svm.predict_proba(test_tfidf)\n",
    "predict_rank = pd.DataFrame({'classes': svm.classes_, 'probs': probs.flatten()})\n",
    "predict_rank = predict_rank.sort_values(by = 'probs', ascending = False)\n",
    "\n",
    "print('top {} predictions for {} is:'.format(top_n, text))\n",
    "\n",
    "predict_rank[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Accuracy score is higher with emoji with \"enough\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emojis with at least 30 tweets\n",
    "enough_emoji = tweets_df.groupby('emoji').count()[tweets_df.groupby('emoji').count()['tweets']>=30]\n",
    "enough_emoji = pd.merge(enough_emoji.reset_index()[['emoji']], tweets_df, on='emoji', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classify_emoji(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.random.seed(1)\n",
    "    \n",
    "    def tfidf(self, X, y, max_features=10000, ngram_range = (1,2)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        tfidf = TfidfVectorizer(max_features=max_features, ngram_range = ngram_range)\n",
    "        tfidf.fit(X_train)\n",
    "        return(tfidf)\n",
    "\n",
    "    def vectorize(self, X, y, max_features=10000, ngram = (1,2)):\n",
    "        tfidf = self.tfidf(X, y, max_features=max_features, ngram = ngram_range)\n",
    "        X_train_tfidf = tfidf.transform(X_train)\n",
    "        X_test_tfidf = tfidf.transform(X_test)\n",
    "        return(X_train_tfidf, X_test_tfidf)\n",
    "    \n",
    "    def nb_model(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        X_train_tfidf, X_test_tfidf = self.vectorize(X, y)\n",
    "        # fit the training dataset on the NB classifier\n",
    "        naive = naive_bayes.MultinomialNB()\n",
    "        naive.fit(X_train_tfidf, y_train)\n",
    "        # predict the labels on validation dataset\n",
    "        predictions_nb = naive.predict(X_test_tfidf)\n",
    "        # Use accuracy_score function to get the accuracy\n",
    "        score = accuracy_score(predictions_nb, y_test)*100\n",
    "        print(\"Naive Bayes Accuracy Score -> \", score)\n",
    "        return(naive)\n",
    "    \n",
    "    def gnb_model(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        X_train_tfidf, X_test_tfidf = self.vectorize(X, y)\n",
    "\n",
    "        gnb = naive_bayes.GaussianNB()\n",
    "        gnb.fit(X_train_tfidf.todense(), y_train)\n",
    "        predictions_gnb = gnb.predict(X_test_tfidf.todense())\n",
    "        \n",
    "        score = accuracy_score(predictions_gnb, y_test)*100\n",
    "        print(\"Gaussian Naive Bayes Accuracy Score -> \", score)\n",
    "        return(gnb)\n",
    "                                    \n",
    "    def svm_model(self, X, y):\n",
    "        # Classifier - Algorithm - SVM\n",
    "        # fit the training dataset on the classifier\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        X_train_tfidf, X_test_tfidf = self.vectorize(X, y)\n",
    "        svm = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto', probability=True)\n",
    "        svm.fit(X_train_tfidf, y_train)\n",
    "        # predict the labels on validation dataset\n",
    "        predictions_svm = svm.predict(X_test_tfidf)\n",
    "        # Use accuracy_score function to get the accuracy\n",
    "        score = accuracy_score(predictions_svm, y_test)*100\n",
    "        print(\"SVM Accuracy Score -> \",score)\n",
    "        return(svm)\n",
    "    \n",
    "    def predict(self, text, X, y, top_n = 3, max_features=10000, ngram_range = (1,2)):\n",
    "        tfidf = self.tfidf(X, y, max_features=max_features, ngram_range = ngram_range)\n",
    "        test_tfidf = tfidf.transform([text])\n",
    "        gnb = self.gnb_model(X, y)\n",
    "        probs = gnb.predict_proba(test_tfidf)\n",
    "        predict_rank = pd.DataFrame({'classes': gnb.classes_, 'probs': probs}).sort_values(by = 'probs', ascending = False)\n",
    "\n",
    "        return(print('top {} predictions for {} is:'.format(top_n, text)),\n",
    "               predict_rank[:top_n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to:\n",
    "    1. grid search\n",
    "    2. more models\n",
    "    3. more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
