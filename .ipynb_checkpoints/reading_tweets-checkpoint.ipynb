{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import unicode_literals\n",
    "import twitter_credentials as cred\n",
    "import tweepy\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import boto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "altered code from https://github.com/janvanzeghbroeck/urban-emoji/blob/master/twitter_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 of 10\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(cred.consumer_key, cred.consumer_secret)\n",
    "auth.set_access_token(cred.access_token, cred.access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "def get_tweets(topic, save_file_name, num_batches=25, num_tweets = 20, to_bucket = False): # num_batches * 100 is total tweets target\n",
    "    tweets = set()\n",
    "    # public_tweets = api.home_timeline()\n",
    "    for i in range(num_batches):\n",
    "        try:\n",
    "            print('Loading', i+1, 'of', num_batches)\n",
    "            for tweet in tweepy.Cursor(api.search, q=topic).items(num_tweets): #100 batches of 20\n",
    "\n",
    "                if tweet.lang == 'en':\n",
    "                    tweets.add(tweet.text) \n",
    "\n",
    "            time.sleep(35) \n",
    "        except:\n",
    "            print('Waiting for API to allow more calls...')\n",
    "            time.sleep(60)\n",
    "            pass\n",
    "\n",
    "    # if to_bucket:\n",
    "        pass\n",
    "    else:\n",
    "        pickle.dump( tweets, open( \"{}.pkl\".format(save_file_name), \"wb\" ) )\n",
    "        print('Succesfully pickled', len(tweets), 'tweets!')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    now = datetime.datetime.today().ctime()\n",
    "    now = re.sub(' ','_',now)\n",
    "    now = re.sub(':','-',now)\n",
    "\n",
    "\n",
    "    # use boto to connect to aws buckets\n",
    "    conn = boto.connect_s3(cred.aws_access_key, cred.aws_access_secret_key)\n",
    "\n",
    "    # what bucket?\n",
    "    bucket_name = 'emoji-tweets'\n",
    "\n",
    "    # check if bucket exists if not make it\n",
    "    if conn.lookup(bucket_name) is None:\n",
    "        b = conn.create_bucket(bucket_name)\n",
    "    else:\n",
    "        b = conn.get_bucket(bucket_name)\n",
    "\n",
    "    simple_words = ['is', 'it', 'the', 'are','abortion', 'rights', 'fire', 'climate', 'Greta', 'Ocasio',\n",
    "                   'ðŸ¤¯', 'ðŸ™Š', 'ðŸ‡°ðŸ‡·', 'ðŸ‡ºðŸ‡¸', 'ðŸ‡©ðŸ‡ª']\n",
    "    \n",
    "    for word in simple_words:\n",
    "        pkl_name = './tweet_data/tweets_{}_{}'.format(now,word)\n",
    "        s3_name = 'tweets_{}_{}.pkl'.format(now,word)\n",
    "        loc_name = './tweet_data/tweets_{}_{}.pkl'.format(now,word)\n",
    "        get_tweets(word, pkl_name, num_batches = 10, num_tweets = 50)\n",
    "\n",
    "        # save the pkl file\n",
    "        file_object = b.new_key(s3_name)#where to save\n",
    "        file_object.set_contents_from_filename(loc_name)\n",
    "\n",
    "        print('Successfully saved {} to S3 bucket {}'.format(s3_name,bucket_name))\n",
    "\n",
    "    \n",
    "    # to read the file\n",
    "    #fil_object.get_contents_to_file('folder/file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir \n",
    "from os.path import isfile, join \n",
    "import pandas as pd\n",
    "mypath = './tweet_data'\n",
    "files = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for i in files:\n",
    "    file = './tweet_data/'+ i\n",
    "    tweets += list(pickle.load(open(file,'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5437"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read this many tweets!\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully pickled 763 tweets and emoji data frame\n"
     ]
    }
   ],
   "source": [
    "# ----- creates the emoji df and adds the unichar\n",
    "def df_emojis():\n",
    "    # create full df_emoji\n",
    "    df = pd.read_pickle('./data/emoji.pkl')\n",
    "\n",
    "    df = pd.DataFrame(df[1:])\n",
    "    df.rename(columns={0: 'unichar'}, inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------ finding the tweets with emojis\n",
    "def yay_no(tweets,df_emojis):\n",
    "    no_moji = []\n",
    "    yay_moji = []\n",
    "    for tweet in tweets:\n",
    "        tweet = str(tweet) #some have type tweepy.models.Status\n",
    "        yay = False\n",
    "        for uni in df_emojis['unichar']:\n",
    "            #if emoji in str(tweet):\n",
    "            if uni in tweet:\n",
    "                yay = True\n",
    "        if yay:\n",
    "            yay_moji.append(tweet)\n",
    "        else: # else statement to create no_moji list\n",
    "            no_moji.append(tweet)\n",
    "    return yay_moji, no_moji\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    tweets = list(set(tweets))\n",
    "\n",
    "    df_emojis = df_emojis()\n",
    "    df_emojis = df_emojis.iloc[0:1013,:] #dont emojis after 1013 yet\n",
    "\n",
    "    yay_moji, no_moji = yay_no(tweets,df_emojis)\n",
    "\n",
    "    pickle.dump( yay_moji, open( \"./data/yay_moji.pkl\", \"wb\"))\n",
    "    pickle.dump( df_emojis, open( \"./data/df_emojis.pkl\", \"wb\"))\n",
    "\n",
    "    print('Succesfully pickled {} tweets and emoji data frame'.format(len(yay_moji)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
