{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import unicode_literals\n",
    "import twitter_credentials as cred\n",
    "import tweepy\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import boto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "altered code from https://github.com/janvanzeghbroeck/urban-emoji/blob/master/twitter_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Loading 8 of 30\n",
      "Loading 9 of 30\n",
      "Loading 10 of 30\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Loading 14 of 30\n",
      "Loading 15 of 30\n",
      "Loading 16 of 30\n",
      "Loading 17 of 30\n",
      "Loading 18 of 30\n",
      "Loading 19 of 30\n",
      "Loading 20 of 30\n",
      "Loading 21 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 22 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 23 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 24 of 30\n",
      "Loading 25 of 30\n",
      "Loading 26 of 30\n",
      "Loading 27 of 30\n",
      "Loading 28 of 30\n",
      "Loading 29 of 30\n",
      "Loading 30 of 30\n",
      "Succesfully pickled 2343 tweets!\n",
      "Successfully saved tweets_Fri_Jun_28_09-31-44_2019_is.pkl to S3 bucket emoji-tweets\n",
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Loading 8 of 30\n",
      "Loading 9 of 30\n",
      "Loading 10 of 30\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Loading 14 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 15 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 16 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 17 of 30\n",
      "Loading 18 of 30\n",
      "Loading 19 of 30\n",
      "Loading 20 of 30\n",
      "Loading 21 of 30\n",
      "Loading 22 of 30\n",
      "Loading 23 of 30\n",
      "Loading 24 of 30\n",
      "Loading 25 of 30\n",
      "Loading 26 of 30\n",
      "Loading 27 of 30\n",
      "Loading 28 of 30\n",
      "Loading 29 of 30\n",
      "Loading 30 of 30\n",
      "Succesfully pickled 2326 tweets!\n",
      "Successfully saved tweets_Fri_Jun_28_09-31-44_2019_it.pkl to S3 bucket emoji-tweets\n",
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 8 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 9 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 10 of 30\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Loading 14 of 30\n",
      "Loading 15 of 30\n",
      "Loading 16 of 30\n",
      "Loading 17 of 30\n",
      "Loading 18 of 30\n",
      "Loading 19 of 30\n",
      "Loading 20 of 30\n",
      "Loading 21 of 30\n",
      "Loading 22 of 30\n",
      "Loading 23 of 30\n",
      "Loading 24 of 30\n",
      "Loading 25 of 30\n",
      "Loading 26 of 30\n",
      "Loading 27 of 30\n",
      "Loading 28 of 30\n",
      "Loading 29 of 30\n",
      "Loading 30 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Succesfully pickled 2389 tweets!\n",
      "Successfully saved tweets_Fri_Jun_28_09-31-44_2019_the.pkl to S3 bucket emoji-tweets\n",
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Loading 8 of 30\n",
      "Loading 9 of 30\n",
      "Loading 10 of 30\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Loading 14 of 30\n",
      "Loading 15 of 30\n",
      "Loading 16 of 30\n",
      "Loading 17 of 30\n",
      "Loading 18 of 30\n",
      "Loading 19 of 30\n",
      "Loading 20 of 30\n",
      "Loading 21 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 22 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 23 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 24 of 30\n",
      "Loading 25 of 30\n",
      "Loading 26 of 30\n",
      "Loading 27 of 30\n",
      "Loading 28 of 30\n",
      "Loading 29 of 30\n",
      "Loading 30 of 30\n",
      "Succesfully pickled 2346 tweets!\n",
      "Successfully saved tweets_Fri_Jun_28_09-31-44_2019_are.pkl to S3 bucket emoji-tweets\n",
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Loading 8 of 30\n",
      "Loading 9 of 30\n",
      "Loading 10 of 30\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 14 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 15 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 16 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 17 of 30\n",
      "Loading 18 of 30\n",
      "Loading 19 of 30\n",
      "Loading 20 of 30\n",
      "Loading 21 of 30\n",
      "Loading 22 of 30\n",
      "Loading 23 of 30\n",
      "Loading 24 of 30\n",
      "Loading 25 of 30\n",
      "Loading 26 of 30\n",
      "Loading 27 of 30\n",
      "Loading 28 of 30\n",
      "Loading 29 of 30\n",
      "Loading 30 of 30\n",
      "Succesfully pickled 366 tweets!\n",
      "Successfully saved tweets_Fri_Jun_28_09-31-44_2019_vegan.pkl to S3 bucket emoji-tweets\n",
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Loading 8 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 9 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 10 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Loading 14 of 30\n",
      "Loading 15 of 30\n",
      "Loading 16 of 30\n",
      "Loading 17 of 30\n",
      "Loading 18 of 30\n",
      "Loading 19 of 30\n",
      "Loading 20 of 30\n",
      "Loading 21 of 30\n",
      "Loading 22 of 30\n",
      "Loading 23 of 30\n",
      "Loading 24 of 30\n",
      "Loading 25 of 30\n",
      "Loading 26 of 30\n",
      "Loading 27 of 30\n",
      "Loading 28 of 30\n",
      "Loading 29 of 30\n",
      "Loading 30 of 30\n",
      "Succesfully pickled 247 tweets!\n",
      "Successfully saved tweets_Fri_Jun_28_09-31-44_2019_âœ¨.pkl to S3 bucket emoji-tweets\n",
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Loading 8 of 30\n",
      "Loading 9 of 30\n",
      "Loading 10 of 30\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Loading 14 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 15 of 30\n",
      "Waiting for API to allow more calls...\n",
      "Loading 16 of 30\n",
      "Loading 17 of 30\n",
      "Loading 18 of 30\n",
      "Loading 19 of 30\n",
      "Loading 20 of 30\n",
      "Loading 21 of 30\n",
      "Loading 22 of 30\n",
      "Loading 23 of 30\n",
      "Loading 24 of 30\n",
      "Loading 25 of 30\n",
      "Loading 26 of 30\n",
      "Loading 27 of 30\n",
      "Loading 28 of 30\n",
      "Loading 29 of 30\n",
      "Loading 30 of 30\n",
      "Succesfully pickled 81 tweets!\n",
      "Successfully saved tweets_Fri_Jun_28_09-31-44_2019_greta.pkl to S3 bucket emoji-tweets\n",
      "Loading 1 of 30\n",
      "Loading 2 of 30\n",
      "Loading 3 of 30\n",
      "Loading 4 of 30\n",
      "Loading 5 of 30\n",
      "Loading 6 of 30\n",
      "Loading 7 of 30\n",
      "Loading 8 of 30\n",
      "Loading 9 of 30\n",
      "Loading 10 of 30\n",
      "Loading 11 of 30\n",
      "Loading 12 of 30\n",
      "Loading 13 of 30\n",
      "Loading 14 of 30\n",
      "Loading 15 of 30\n",
      "Loading 16 of 30\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(cred.consumer_key, cred.consumer_secret)\n",
    "auth.set_access_token(cred.access_token, cred.access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "\n",
    "def get_tweets(topic, save_file_name, num_batches=25, num_tweets = 20, to_bucket = False): # num_batches * 100 is total tweets target\n",
    "    tweets = set()\n",
    "    # public_tweets = api.home_timeline()\n",
    "    for i in range(num_batches):\n",
    "        try:\n",
    "            print('Loading', i+1, 'of', num_batches)\n",
    "            for tweet in tweepy.Cursor(api.search, q=topic).items(num_tweets): #100 batches of 20\n",
    "\n",
    "                if tweet.lang == 'en':\n",
    "                    tweets.add(tweet.text) \n",
    "\n",
    "            time.sleep(35) \n",
    "        except:\n",
    "            print('Waiting for API to allow more calls...')\n",
    "            time.sleep(60)\n",
    "            pass\n",
    "\n",
    "    # if to_bucket:\n",
    "        pass\n",
    "    else:\n",
    "        pickle.dump( tweets, open( \"{}.pkl\".format(save_file_name), \"wb\" ) )\n",
    "        print('Succesfully pickled', len(tweets), 'tweets!')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    now = datetime.datetime.today().ctime()\n",
    "    now = re.sub(' ','_',now)\n",
    "    now = re.sub(':','-',now)\n",
    "\n",
    "\n",
    "    # use boto to connect to aws buckets\n",
    "    conn = boto.connect_s3(cred.aws_access_key, cred.aws_access_secret_key)\n",
    "\n",
    "    # what bucket?\n",
    "    bucket_name = 'emoji-tweets'\n",
    "\n",
    "    # check if bucket exists if not make it\n",
    "    if conn.lookup(bucket_name) is None:\n",
    "        b = conn.create_bucket(bucket_name)\n",
    "    else:\n",
    "        b = conn.get_bucket(bucket_name)\n",
    "\n",
    "    simple_words = ['is', 'it', 'the', 'are','vegan','âœ¨', 'greta', 'ocasio', 'climate']\n",
    "    \n",
    "    for word in simple_words:\n",
    "        pkl_name = './tweet_data/tweets_{}_{}'.format(now,word)\n",
    "        s3_name = 'tweets_{}_{}.pkl'.format(now,word)\n",
    "        loc_name = './tweet_data/tweets_{}_{}.pkl'.format(now,word)\n",
    "        get_tweets(word, pkl_name, num_batches = 30, num_tweets = 100)\n",
    "\n",
    "        # save the pkl file\n",
    "        file_object = b.new_key(s3_name)#where to save\n",
    "        file_object.set_contents_from_filename(loc_name)\n",
    "\n",
    "        print('Successfully saved {} to S3 bucket {}'.format(s3_name,bucket_name))\n",
    "\n",
    "    \n",
    "    # to read the file\n",
    "    #fil_object.get_contents_to_file('folder/file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir \n",
    "from os.path import isfile, join \n",
    "import pandas as pd\n",
    "mypath = './tweet_data'\n",
    "files = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for i in files:\n",
    "    file = './tweet_data/'+ i\n",
    "    tweets += list(pickle.load(open(file,'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20732"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read this many tweets!\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully pickled 3909 tweets and emoji data frame\n"
     ]
    }
   ],
   "source": [
    "# ----- creates the emoji df and adds the unichar\n",
    "def df_emojis():\n",
    "    # create full df_emoji\n",
    "    df = pd.read_pickle('./data/df_emoji.pkl')\n",
    "    return df\n",
    "\n",
    "# ------------ finding the tweets with emojis\n",
    "def yay_no(tweets,df_emojis):\n",
    "    no_moji = []\n",
    "    yay_moji = []\n",
    "    for tweet in tweets:\n",
    "        tweet = str(tweet) #some have type tweepy.models.Status\n",
    "        yay = False\n",
    "        for uni in df_emojis['unichar']:\n",
    "            #if emoji in str(tweet):\n",
    "            if uni in tweet:\n",
    "                yay = True\n",
    "        if yay:\n",
    "            yay_moji.append(tweet)\n",
    "        else: # else statement to create no_moji list\n",
    "            no_moji.append(tweet)\n",
    "    return yay_moji, no_moji\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    tweets = list(set(tweets))\n",
    "\n",
    "    df_emojis = df_emojis()\n",
    "\n",
    "    yay_moji, no_moji = yay_no(tweets,df_emojis)\n",
    "\n",
    "    pickle.dump( yay_moji, open( \"./data/yay_moji.pkl\", \"wb\"))\n",
    "    pickle.dump( df_emojis, open( \"./data/df_emojis.pkl\", \"wb\"))\n",
    "\n",
    "    print('Succesfully pickled {} tweets and emoji data frame'.format(len(yay_moji)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19702"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_moji) + len(yay_moji)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
